\documentclass{article}

%----------------------------------------
% Packages
%----------------------------------------
\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath,amsbsy,amssymb,amsfonts,amsthm}
\usepackage{nicefrac}
\usepackage{mathtools}
\usepackage{color}
\usepackage{xspace} % Correct macro spacing
\usepackage[numbers]{natbib} % For citations
\usepackage{times}
\usepackage{textcomp}
\usepackage{graphicx,subfigure}
%\usepackage[small,bf]{caption}
\usepackage{algorithm,algorithmic} 
\usepackage{hyperref}
\usepackage{comment}

\usepackage{mathrsfs}

\usepackage{xcolor}
\usepackage{shadethm}

\usepackage{fancyhdr}
\usepackage{wrapfig}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{positioning}
\usetikzlibrary{decorations.pathreplacing}
\pagestyle{fancy}
\lhead{This is my name}
\rhead{this is page \thepage}

\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{IFT 6085 - Theoretical principles for deep learning}
\rhead{Lecture 2: January 10, 2019}


\newshadetheorem{thm}{Theorem}
\newshadetheorem{defn}[thm]{Definition}
\newshadetheorem{assm}[thm]{Assumption}
\newshadetheorem{prop}[thm]{Property}
\newshadetheorem{eg}[thm]{Example}


\definecolor{shadethmcolor}{HTML}{F0F0F0}
%\definecolor{shadethmcolor}{HTML}{EDEDED}
%\definecolor{shadethmcolor}{HTML}{EDF8FF}
%\definecolor{shaderulecolor}{HTML}{EDF8FF}
%\definecolor{shaderulecolor}{HTML}{45CFFF}
\setlength{\shadeboxrule}{.4pt}


\setlength\parindent{0pt}

% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
\newcommand{\theHalgorithm}{\arabic{algorithm}}

%----------------------------------------
% Standard macros
%----------------------------------------


%----------------------------------------
% Project-specific macros
%----------------------------------------

%----------------------------------------
% Header
%----------------------------------------
\title{IFT 6085 - Lecture 9 \\ Stability and Generalization}
\date{}

%----------------------------------------
% Document
%----------------------------------------
\begin{document} 

%----------------------------------------
% Abstract
%----------------------------------------
\maketitle

\vspace{-0.5in}
\begin{center}
This version of the notes has not yet been thoroughly checked.
Please report any bugs to the scribes or instructor.
\end{center}
\vspace{0.2in}

\textbf{Scribes}\hfill
\textbf{Instructor:}  Ioannis Mitliagkas\\
\textbf{Winter 2019:} Nishanth V Anand, Parviz Haggi\\
\textbf{Winter 2018:} Isabela Albuquerque and Nithin Vasisth


%----------------------------------------
% Body
%----------------------------------------

\newcommand{\infgc}{\inf_{g \in \mathcal{C}}}
\newcommand{\supgc}{\sup_{g \in \mathcal{C}}}

\newcommand{\Prob}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\reals}{\mathbb{R}}

\section{Summary of the previous lecture}
Previously we discussed the idea behind a few bounds in Statistical Learning Theory, the more advanced one being PAC-based Learning Theory. There we saw that we have to commit to a prior distribution on a hypothesis (P) and choose the posterior hypothesis (Q) after seeing the data. This is a powerful method as different choices of prior and posterior hypotheses can be made, each resulting in a new bound without us touching the algorithm. 
In a coming lecture we will discuss a concrete example of a PAC-based bound for Neural Networks. There, the discussion will also include the notion of stability-based bounds, which is the subject of this lecture.\\


The algorithm-agnostic bounds take into account the complexity of the hypothesis class of functions $\mathcal{H}$, without involving the algorithm or the actual distribution of the data. To put it correctly, for the Hoeffding bound to work, the distribution of the data was included in the analysis through the assumption that the data points were i.i.d.. Apart from that, however, no other information about the distribution was used. \\


Although we will not delve into the subject of distribution-agnostic bounds, in this lecture we will introduce the first class of bounds that take into account the algorithm. The analysis is largely dependent on the notion of stability which, simply put, says that a change in data distribution does not change the predictions. 



\section{PAC Learning}
The setting of the Probably Approximately Correct (PAC) learning involves the same definitions as before but with a slight change in notation that will help us in our analysis: We introduce $z_i=(x_i,y_i)$ i.e we give each pair a name. 

\begin{defn}[Training set]
The training set consists of a set of values $z_i=(x_i,y_i)$, where $x_i$ represents a feature vector and $y_i$ the label of the $i$-th sample. Furthermore, $z_i$ are assumed to be i.i.d. and sampled from an unknown data distribution $\mathcal{D}$. 
\[
	S = \{z_1, z_2, \dots, z_n\}
\]
\end{defn}
 Next we define the loss function slightly differently. 
\begin{defn}[Loss Function] The loss function $\ell(h(x),y)$ is defined as a function that takes two labels and produces 0 or some constant M. 
\[
	\ell: \mathcal{Y} \times \mathcal{Y} \longrightarrow [0,M].
\]
Equivalently, defining $\mathcal{Z}\overset{\Delta}{=}\mathcal{X}\times \mathcal{Y}$,  the loss function $\ell (h,z)$  can be defined as 
\[
	\ell: \mathcal{H} \times \mathcal{Z} \longrightarrow [0,M].
\]
\end{defn}
Notice that, unlike its previous definition, the loss function is now assumed to be bounded by some constant $M$ instead of 1. 
Note also that $\mathcal{Z}$ is the space of all tuples $(x_i,y_i) $ and that the previous loss function $\ell(h(x),y)$ is now denoted as $\ell(h,z)$


\section{Stability}
We start this section by introducing two new notions, the first of which is the notion of  perturbed datasets. This is a step-stone in introducing a new class of bounds that unlike the   \textit{algorithm-agnostic} bounds, are dependent on the algorithm. 
\begin{defn}[A Perturbed dataset] Given a dataset $S$ (i.i.d.), a perturbed dataset $S^{i, z}$ is defined as
\[
	S^{i,z} = \{z_1, z_2, \dots, z_{i-1}, z, z_{i+1}, \dots, z_{n} \}.
\]
\end{defn}
According to this definition, a perturbed dataset $S^{i,z}$ is defined by a set whose $i$-th element is replaced by an arbitrary sample $z$. 
We will see that some learning algorithms give essentially a hypothesis that makes the same predictions no matter if the algorithm is trained on the original dataset or the perturbed one.
\begin{defn}[Algorithm]
A learning algorithm $\mathcal{A}$ is defined as the following mapping
\[
\mathcal{A}: (\mathcal{X} \times \mathcal{Y})^n \rightarrow \mathcal{H}.
\]
\end{defn}
It is clear from this definition that an algorithm $\mathcal{A}$ used on a dataset $S$, produces a hypothesis class $h_{S}$ i.e. $h_S = \mathcal{A}(S)$.


\begin{defn}[Uniform stability] An algorithm $\mathcal{A}$ is $\beta$-uniformly stable with respect to the loss function $\ell$ if
\[\forall (S,z) \in \mathcal{Z}^{n+1}\;\; \text{and} \;\;\forall i \in \{1, 2, \dots, n\}:\;\;\;
	\sup_{z' \in \mathcal{Z}} | \ell(h_S,z') - \ell(h_{S^{i, z}},z' ) | \le \beta.
\]
\end{defn}
This definition measures stability based on how much the predictions or the losses on the predictions change when we train using the perturbed dataset. Notice the two hypotheses: $h_S$ that we get when using the unperturbed dataset and $h_{S^{i,z}}$ that we derive from the perturbed dataset. This definition holds for any dataset but there is no assumption on what particular distribution $S$ comes from. The notion of a $\beta$-uniformly stable algorithm is reminiscent of the familiar notion of Lipschitz property on the loss function. Intuitively, an algorithm with this property can be understood as one that produces a hypothesis such that the loss function $\ell$ is not drastically affected by perturbing the dataset in this manner.\\ 
 
 %It is important to emphasize that this is a uniform bound because it is valid for all datasets $S$ and indexes $i$. \\ %We usually do not need such a strong statement, we can restrict the values of $S$ and $z$ to be within the region of the data.

%*The concept of robustness is not the same




 
\begin{defn}[Defect]\label{defect}
\[
	D[h_S] = R[h_{S}] - \hat{R}_{S}[h_S].
\]
\end{defn}
Defect $D[h_S]$ for a hypothesis $h_S$ derived from an algorithm after seeing the dataset $S$ is defined as  the difference between the population risk and the empirical risk. \\

While it is true that 
for an arbitrary hypothesis $h \in \mathcal{H}$,\;\;\; 
	$\mathbb{E}[{D}[h]]=\mathbb{E}[R[h] - \hat{R}_S[h]]=0$,
this is not the case for $D[h_S]$ i.e. we will generally have   
\[
	\mathbb{E}[D[h_S]] \neq 0.
\]
This is due to second term $\hat{R}_{S}[h_S]$ which evaluates the empirical risk on the same  dataset that is also used to extract the hypothesis. 

\begin{align*}
    \mathbb{E}_S[\hat{R}_{S}[h_S]]
    &=\mathbb{E}_S[\frac{1}{n}\sum_{i=1}^n \ell(h_S(x_{i}),y_{i})]\\
    &=\frac{1}{n}\sum_{i=1}^n\mathbb{E}_S[ \ell(h_S(x_{i}),y_{i})]\\
    &\neq \mathbb{E}_S[\mathbb{E}_{z \sim \mathcal{D}} \left[\ell(h_S(x),y)\right]]\overset{\Delta}{=}\mathbb{E}_S[{R}[h_S]]
\end{align*}
In the second line of the above equation, the expectation value is evaluated based on the dataset $S$ and the hypothesis extracted from it.  
The expectation value of the population risk on the learned hypothesis (third line) is evaluated on a random variable $z$, independent from $S$ and drawn from the distribution that the dataset is assumed to come from. 
The two entities are generally completely different simply because we need the independence assumption for the population risk.\\ 

A meaningful question to ask here is whether the expectation value of the defect, which we showed is generally non-zero, can be bounded. In what follows, we will show that the answer is yes and that this can be done under certain conditions.  
  	

\begin{thm}[Bounding the expectation value of the defect]\label{defec_bound}
If $\mathcal{A}$ is a $\beta$-uniformly stable algorithm, then 
\[
	-\beta \le \mathbb{E}_{S}[D[h_S]] \le \beta.
\]
\end{thm}
\begin{proof}
We prove this for one side of the inequality:  
	 $\mathbb{E}_{S}[D[h_S]] \le \beta$

\begin{align*}
    \mathbb{E}_S[D_{S}[h_S]]
    &=\mathbb{E}_S\Big[
    \hat R_S[h_S]-R[h_S]\Big]\\
    &=\mathbb{E}_S
    \Big[\frac{1}{n}\sum_{i=1}^n \ell(h_S,z_{i})-\mathbb{E}_z\ell(h_S,z)\Big]\\
    &=\mathbb{E}_{S,z}
    \Big[\frac{1}{n}\sum_{i=1}^n \Big[\ell(h_S,z_{i})-\ell(h_S,z)\Big]\Big]\\
    &=\mathbb{E}_{S,z}
    \Big[\frac{1}{n}\sum_{i=1}^n \Big[\ell(h_{S^{i,z}},z)-\ell(h_S,z)\Big]\Big]\\
    &\leq \mathbb{E}_{S,z}
    \Big[\frac{1}{n}\sum_{i=1}^n\beta\Big]=\beta
\end{align*}	 
\end{proof}
In the second line we inserted the population risk as defined  above: $R[h_S]=\mathbb{E}_z\ell(h_S,z)$ In the third line, we used Fubini's theorem which allows us to change the order of the two expectations $\mathbb{E}_{S}$ and $\mathbb{E}_{z}$ as they are independent and bounded (due to the fact that the loss function is bounded by $M$). In the fourth line we rename a variable and finally we calculate the upper bound by using the definition of $\beta$-stability.  In conclusion we have proven the following relationship between the expectation values of the empirical and population risks: 
\begin{prop}[The relationship between the empirical and the population risk]
\[
	\mathbb{E}_{S}[R[h_{S}]] \le \mathbb{E}_{S}[\hat{R}_{S}[h_S]] + \beta.
\]
\end{prop}








 
 %It is important to emphasize that this is a uniform bound because it is valid for all datasets $S$ and indexes $i$. \\ %We usually do not need such a strong statement, we can restrict the values of $S$ and $z$ to be within the region of the data.

%*The concept of robustness is not the same







Note that this is a bound on the  \textit{expectation} value of the population risk. However, even if the expectation values of $R[h_S]$ and $\hat{R}_S[h_S]$ are close, this bound does not necessarily hold for all possible $h_S$. 
In what follows, we will demonstrate that for a $\beta$-uniformly stable algorithm, the population risk  $R[h_S]$ can be shown to be bounded above by the empirical risk $\hat{R}_S[h_S]$ plus certain other quantities. To do so we will first introduce McDiramid's inequality, a well known concentration inequality.

\begin{thm}[McDiarmid's inequality]
Let $V_1, V_2, V_3, \dots , V_n \in \mathcal{V}$ be independent random variables, and $v_1, v_2,v_3,\dots,v_n$ denote specific values (not independent). If a function $f: \mathcal{V}^n \to \mathbb{R}$ has the property that $\forall i \in \{1, 2, \dots, n\}$, 
\[
	\sup_{v_1, v_2, \dots, v_n, v_i{'}}{\biggl|f(v_1, v_2, \dots, v_n) - f(v_1, \dots,v_{i-1}, v_i^{'}, v_{i+1}, \dots v_n)\biggr|} \leq c_i
\]
then
\[
    \mathbb{P}\biggl(\bigl|f(V_1, V_2, \dots , V_n) - \mathbb{E}f(V_1, V_2, \dots , V_n)\bigr|>\epsilon\biggr) \leq 2 \exp{\frac{-2 \epsilon^2}{\sum_{i}{c_{i}^2}}}
\]
\end{thm}

\begin{proof}
See Appendix D.2 of \cite{mohri2012foundations}.
\end{proof}
This bound is useful because if we prove that an algorithm is $\beta$ stable then we will have this property on a specific function.
\begin{thm}[Bound for the defect]\label{def_bound} Let "A" be a $\beta$ uniformly stable learning algorithm with respect to a loss function $\ell: \mathcal{Y} \times \mathcal{Y} \rightarrow [0, M]$. The absolute difference of the defect calculated on a dataset $S$ and on a perturbed version of this dataset $S^{i, z}$ is bounded by
\[
\biggl|D[h_S] - D[h_{S^{i,z}}]\biggr| \leq 2\beta + \frac{M}{n}.
\]
\end{thm}
This theorem gives us a bound on the gap between the actual dataset and the perturbed dataset. This is used as a stepping stone in the final theorem. In other words, the theorem tells us that the population risk and the empirical risk are close to each other. This theorem is an example of the use case of McDiramid's inequality.
\begin{proof}
Let us expand the following quantity using their definition: 
\begin{equation}\label{def_risk}
|D[h_S] - D[h_{S^{i,z}}]| = |R[h_S] - \hat{R}_S[h_S] - R[h_{S^{i,z}}] + \hat{R}_{S^{i,z}}[h_{S^{i,z}}]|
\end{equation}
Using the triangle inequality:
\begin{equation}
|D[h_S] - D[h_{S^{i,z}}]| \leq |R[h_S] - R[h_{S^{i,z}}]| + |\hat{R}_{S^{i,z}}[h_{S^{i,z}}] - \hat{R}_S[h_S]| \label{PartAB}
\end{equation}
Now, we use the $\beta$ uniform stability of algorithm $\mathcal{A}$ with respect to the loss function $\ell$ to find a bound for $|R[h_S] - R[h_{S^{i,z}}]|$:
\begin{equation}
\begin{split}
\bigl|R[h_S] - R[h_{S^{i,z}}]\bigr| &= \bigl| \mathbb{E}_{z' \sim D} [\ell(h_S, z')] - \mathbb{E}_{z'} [\ell(h_{S^{i,z}}, z')] \bigr| \\ 
&= \bigl|\mathbb{E}_{z' \sim D} [\ell(h_S, z') - \ell(h_{S^{i,z}}, z'))]\bigr| \\
& \leq \beta \label{partA}
\end{split}
\end{equation}
We can find a bound for $|\hat{R}_{S^{i,z}}[h_{S^{i,z}}] - \hat{R}_S[h_S]|$ by expanding the quantities using their definition
\begin{equation}
\begin{split}
\bigl|\hat{R}_{S^{i,z}}[h_{S^{i,z}}] - \hat{R}_S[h_S]\bigr| &= \biggr|\frac{1}{n}\sum_{j=1}^{n}\ell(h_{S^{i,z}}, z_j) - \frac{1}{n}\ell(h_{S^{i,z}}, z_i) + \frac{1}{n}\ell(h_{S^{i,z}}, z) - \frac{1}{n}\sum_{j=1}^{n}\ell(h_S, z_j)\biggl|\\
&\leq \frac{1}{n} \biggl|\ell(h_{S^{i,z}}, z) - \ell(h_{S^{i,z}}, z_i)\biggr| + \frac{1}{n}\sum_j\biggl|\ell(h_{S^{i,z}}, z_j) -  \ell(h_S, z_j)\biggr| \\
&\leq \frac{M}{n} + \beta \label{partB}
\end{split}
\end{equation}
We now plug in the results obtained from Eq \ref{partA} and Eq \ref{partB} in Eq \ref{PartAB} to get the proof.
\begin{equation}\label{proof1}
\begin{split}
|D[h_S] - D[h_{S^{i,z}}]| & \leq 2\beta + \frac{M}{n}
\end{split}
\end{equation}
\end{proof}

\begin{thm}[Bound for the population risk of a $\beta$-uniformly stable algorithm]\label{risk_bound}
Consider a $\beta$-uniformly stable algorithm $\mathcal{A}$ with respect to a loss function $\ell: \mathcal{Y} \times \mathcal{Y} \rightarrow [0, M]$ and a hypothesis $h_S$ with $|S| = n$. The following bound holds with probability $1-\delta$: 
\[
R[h_S] \leq \hat{R}_S[h_S] + \beta + \left(n\beta + \frac{M}{2} \right) \sqrt{\frac{2\log\frac{2}{\delta}}{n}}.
\]
\end{thm}
Note that:
\begin{itemize}
    \item $\hat{R}_S[h_S]$ is empirical risk
    \item $\beta$ is from theorem \ref{defec_bound}
    \item $\left(n\beta + \frac{M}{2} \right) \sqrt{\frac{2\log\frac{2}{\delta}}{n}}$ is a concentration inequality (McDiramid's)
\end{itemize}
\begin{proof}
Using theorem \ref{def_bound}, we state McDiarmid's inequality for $D[h_S]$ and then use this result to find a high probability bound for $D[h_S]$:
\begin{equation}
\sup_{S, i, z} |D[h_S] - D[h_{S^{i, z}}]| \leq 2\beta + \frac{M}{n}
\end{equation}
then 
\begin{equation}
\begin{split}
P(|D[h_S] - \mathbb{E}[D[h_S]]| > \epsilon) & \leq 2\exp \left(\frac{-2\epsilon^2}{\sum_{i=1}^{n}  \left( 2\beta + \frac{M}{n} \right)^2 } \right), \\
& = 2\exp \left(\frac{-2n\epsilon^2}{\left( 2n\beta + M \right)^2 } \right), \\
& = 2\exp \left(\frac{-2n\epsilon^2}{4\left(n\beta + \frac{M}{2} \right)^2 } \right), \\
& = 2\exp \left(\frac{-n\epsilon^2}{2\left(n\beta + \frac{M}{2} \right)^2 } \right).
\end{split}
\end{equation}

Denoting $\delta = 2\exp \left(\frac{-n\epsilon^2}{2\left(n\beta + \frac{M}{2} \right)^2 } \right)$ and solving this equation for $\epsilon$, we obtain:

\begin{equation}\label{epsilon}
\begin{split}
\delta = 2\exp \left(\frac{-n\epsilon^2}{2\left(n\beta + \frac{M}{2} \right)^2 } \right) & \Rightarrow n\epsilon^2 = 2\log\frac{2}{\delta}\left(n\beta + \frac{M}{2} \right)^2 \\
& \Rightarrow \epsilon = \left(n\beta + \frac{M}{2} \right) \sqrt{\frac{2\log\frac{2}{\delta}}{n}}.
\end{split}
\end{equation}
Thus, with probability $1-\delta$ 
\begin{equation*}
\begin{split}
|D[h_S] - \mathbb{E}[D[h_S]]| &\leq \epsilon \\
D[h_S] &\leq \mathbb{E}[D[h_S]] + \epsilon \\
D[h_S] &\leq \beta + \epsilon
\end{split}
\end{equation*}
Replacing $\epsilon$ by the result previously obtained in Eq. \ref{epsilon}
\begin{equation}
D[h_S] \leq \beta + \left(n\beta + \frac{M}{2} \right) \sqrt{\frac{2\log\frac{2}{\delta}}{n}}
\end{equation}
we finally get the desired result,
\begin{equation}
R[h_S] \leq \hat{R}_S[h_S] + \beta + \left(n\beta + \frac{M}{2} \right) \sqrt{\frac{2\log\frac{2}{\delta}}{n}}
\end{equation}
\end{proof}
Notice that by making use of certain properties of an algorithm we can get a good bound.


The following illustration represents a summary of the bounds stated in Theorem \ref{defec_bound} and \ref{risk_bound} (in terms of the defect):
\begin{figure}[H]\centering
  \begin{tikzpicture}[scale=3]
    \draw[->] (-1,0) -- (1,0);
    \draw[dashed] (-0.7,0) -- (-0.7,0.25);
    \draw[dashed] (0.7,0) -- (0.7,0.25);
	\draw[-] (-0.3,-0.03) -- (-0.3,0.03);
    \draw[] (-0.3,-0.03) node[below=-0.1cm] {\small$-\beta$};
    \draw[-] (0.3,-0.03) -- (0.3,0.03);
    \draw[] (0.3,-0.03) node[below=-0.1cm] {\small$\beta$};
    \draw[-] (-0.7,-0.03) -- (-0.7,0.03);
    \draw[] (-0.7,-0.03) node[below=-0.1cm] {\small$-\beta-\epsilon$};
    \draw[-] (0.7,-0.03) -- (0.7,0.03);
    \draw[] (0.7,-0.03) node[below=-0.1cm] {\small$\beta+\epsilon$};
    \draw [decorate, decoration={brace, amplitude=10pt}] (-0.7,0.25) -- (0.7,0.25) node [black, midway, yshift=0.6cm] {\footnotesize $D[h_S]$ (w.p. $1-\delta$)};
    \draw [decorate, decoration={brace, amplitude=10pt}] (-0.3,0.05) -- (0.3,0.05) node [black, midway, yshift=0.55cm] {\footnotesize $\mathbb{E}[D[h_S]]$};
  \end{tikzpicture}
\end{figure}
One can observe that despite the fact the bound for $\mathbb{E}[D[h_S]]$ is tighter, we have no guarantees that the actual of $D[h_S]$ lies in the interval $\left[-\beta, \beta \right]$. On the other hand, it possible to assure with probability $1-\delta$ will be in $\left[-\beta-\epsilon, \beta+\epsilon \right]$.


%\subsection*{5.2 Noise and Fast Rates}
%
%\begin{prop}[Key Property]
%\[
%	\mathrm{Var}(f) \leq Pf
%\]
%\end{prop}
%Allows faster rates of convergence for $L(g_n^*)- \inf_{g \in \mathcal{C}} L(g)$.
%
%For example, when $\infgc L(g) =0$, then
%\[
%	L(g^*_n) - \infgc L(g) \ll \supgc (L(g) - L_n(g)).
%\]

%----------------------------------------
% \section*{Acknowledgments} 

%----------------------------------------
\bibliographystyle{abbrvnat}
\bibliography{Refs/lec9}
%----------------------------------------
\end{document}